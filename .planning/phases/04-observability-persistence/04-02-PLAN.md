---
phase: 04-observability-persistence
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - src/index.ts
  - src/api/routes/chat.ts
autonomous: true

must_haves:
  truths:
    - "Every non-streaming request is logged with provider, model, tokens, latency, and HTTP status"
    - "Every streaming request captures token usage from the final SSE chunk and logs it"
    - "Request logging does not add latency to HTTP responses (fire-and-forget)"
    - "Database is initialized at startup and closed on graceful shutdown"
    - "Streaming requests include stream_options.include_usage for token capture"
  artifacts:
    - path: "src/index.ts"
      provides: "DB initialization, RequestLogger creation, graceful shutdown db.close()"
      contains: "initializeDatabase"
    - path: "src/api/routes/chat.ts"
      provides: "Fire-and-forget request logging for both streaming and non-streaming"
      contains: "setImmediate"
  key_links:
    - from: "src/index.ts"
      to: "src/persistence/db.ts"
      via: "initializeDatabase() call at bootstrap"
      pattern: "initializeDatabase"
    - from: "src/index.ts"
      to: "src/persistence/schema.ts"
      via: "migrateSchema() call after DB init"
      pattern: "migrateSchema"
    - from: "src/index.ts"
      to: "src/api/routes/chat.ts"
      via: "passes RequestLogger to createChatRoutes()"
      pattern: "createChatRoutes.*requestLogger|RequestLogger"
    - from: "src/api/routes/chat.ts"
      to: "src/persistence/request-logger.ts"
      via: "calls requestLogger.logRequest() inside setImmediate"
      pattern: "requestLogger\\.logRequest"
---

<objective>
Wire the SQLite persistence layer into the application: initialize DB at startup, inject RequestLogger into chat routes, add fire-and-forget logging for both streaming and non-streaming completions, and capture streaming token usage.

Purpose: This connects the persistence module (04-01) to the live request flow. After this plan, every chat completion request (streaming and non-streaming) produces a database log entry with full metadata.

Output: Modified src/index.ts with DB bootstrap/shutdown, modified src/api/routes/chat.ts with fire-and-forget logging and streaming token capture.
</objective>

<execution_context>
@C:\Users\danen\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\danen\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-observability-persistence/04-RESEARCH.md
@.planning/phases/04-observability-persistence/04-01-SUMMARY.md
@src/index.ts
@src/api/routes/chat.ts
@src/persistence/request-logger.ts
@src/persistence/db.ts
@src/persistence/schema.ts
@src/chain/types.ts (ChainResult, StreamChainResult)
@src/shared/types.ts (Usage interface)
@src/streaming/sse-parser.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire DB initialization into bootstrap and shutdown</name>
  <files>src/index.ts</files>
  <action>
Modify `src/index.ts` to initialize the database at startup and close it on shutdown.

**Imports to add** (after existing imports):
```typescript
import { initializeDatabase } from './persistence/db.js';
import { migrateSchema } from './persistence/schema.js';
import { RequestLogger } from './persistence/request-logger.js';
import { UsageAggregator } from './persistence/aggregator.js';
```

**After the manual rate limit registration block** (after `if (manualLimitCount > 0)` log), add DB initialization:
```typescript
// --- Initialize observability database ---
const db = initializeDatabase(config.settings.dbPath);
migrateSchema(db);
const requestLogger = new RequestLogger(db);
const aggregator = new UsageAggregator(db);
```

**Update createChatRoutes call** to pass requestLogger as a new parameter:
Change: `createChatRoutes(chains, tracker, registry, config.settings.defaultChain)`
To: `createChatRoutes(chains, tracker, registry, config.settings.defaultChain, requestLogger)`

**Update the shutdown function** to close the database:
Add `db.close()` after `tracker.shutdown()` but before `server.close()`. Log it:
```typescript
const shutdown = () => {
  logger.info('Shutting down...');
  tracker.shutdown();
  db.close();
  logger.info('Database closed');
  server.close(() => {
    logger.info('Server closed');
    process.exit(0);
  });
};
```

Note: The `aggregator` variable will be used in plan 04-03 when stats routes are mounted. For now it's created but not yet passed to any route. That's fine -- it prepares for the next plan. If TypeScript warns about unused variable, either suppress with `void aggregator` or leave it (it won't error with noUnusedLocals off, which is typical). Actually, check tsconfig -- if noUnusedLocals is true, add a comment `// Used in 04-03 stats routes` and prefix with underscore or use void. Simplest: just keep it, the next plan runs immediately after.

Actually, to avoid any potential issue, do NOT create the aggregator yet. Only create db, run migration, and create requestLogger. The aggregator will be created in 04-03 when stats routes are added. This keeps the change minimal.
  </action>
  <verify>
Run `npx tsc --noEmit`. Verify no type errors. The app should start cleanly with `npx tsx src/index.ts` (Ctrl+C to stop) and create the ./data/observability.db file with WAL mode enabled.
  </verify>
  <done>Database initializes at startup with WAL mode, schema migration runs, RequestLogger is instantiated and passed to chat routes, database closes on graceful shutdown.</done>
</task>

<task type="auto">
  <name>Task 2: Add fire-and-forget request logging to chat routes</name>
  <files>src/api/routes/chat.ts</files>
  <action>
Modify `src/api/routes/chat.ts` to accept RequestLogger and log every request.

**Update function signature:**
Change `createChatRoutes` to accept a 5th parameter:
```typescript
import { RequestLogger } from '../../persistence/request-logger.js';
import type { Usage } from '../../shared/types.js';

export function createChatRoutes(
  chains: Map<string, Chain>,
  tracker: RateLimitTracker,
  registry: ProviderRegistry,
  defaultChainName: string,
  requestLogger: RequestLogger,
)
```

**Non-streaming path logging:**
After `c.header('X-429chain-Attempts', ...)` and before `return c.json(result.response)`, add fire-and-forget logging:
```typescript
// Fire-and-forget: log request without blocking response
setImmediate(() => {
  try {
    requestLogger.logRequest({
      timestamp: Date.now(),
      chainName: chain.name,
      providerId: result.providerId,
      model: result.model,
      promptTokens: result.response.usage.prompt_tokens,
      completionTokens: result.response.usage.completion_tokens,
      totalTokens: result.response.usage.total_tokens,
      latencyMs: result.latencyMs,
      httpStatus: 200,
      attempts: result.attempts.length + 1,
    });
  } catch (error) {
    logger.error({ error }, 'Failed to log request');
  }
});
```

**Streaming path -- inject stream_options for token capture:**
In the streaming branch, after stripping the model field (`const { model: _model, ...streamBody } = body;`), add `stream_options: { include_usage: true }` to the request body sent upstream. Modify:
```typescript
const { model: _model, ...streamBody } = body;
// Inject stream_options to capture token usage in final chunk
const streamRequest = {
  ...streamBody,
  stream_options: { include_usage: true },
} as ChatCompletionRequest;
```
Then pass `streamRequest` instead of `streamBody as ChatCompletionRequest` to `executeStreamChain`.

**Streaming path -- capture usage from final SSE chunk:**
Inside the `streamSSE` callback, before the streaming loop, declare:
```typescript
let capturedUsage: Usage | null = null;
const streamStart = performance.now();
```

Inside the `for (const data of result.events)` loop, before `await stream.writeSSE({ data })`, try to parse usage from each event:
```typescript
// Check if this chunk contains usage data (final chunk from OpenAI)
try {
  const parsed = JSON.parse(data);
  if (parsed.usage && typeof parsed.usage.total_tokens === 'number') {
    capturedUsage = parsed.usage as Usage;
  }
} catch {
  // Not JSON or doesn't have usage -- normal content chunk, continue
}
```

After `await stream.writeSSE({ data: '[DONE]' })` (inside `if (result.done)` block), add logging:
```typescript
// Fire-and-forget: log streaming request with captured usage
const streamLatencyMs = performance.now() - streamStart;
setImmediate(() => {
  try {
    requestLogger.logRequest({
      timestamp: Date.now(),
      chainName: chain.name,
      providerId: streamResult.providerId,
      model: streamResult.model,
      promptTokens: capturedUsage?.prompt_tokens ?? 0,
      completionTokens: capturedUsage?.completion_tokens ?? 0,
      totalTokens: capturedUsage?.total_tokens ?? 0,
      latencyMs: streamLatencyMs,
      httpStatus: 200,
      attempts: streamResult.attempts.length + 1,
    });
  } catch (error) {
    logger.error({ error }, 'Failed to log streaming request');
  }
});
```

Note: `performance.now()` is used for latency measurement (same as chain router). The `streamStart` is captured at the beginning of the SSE streaming callback, measuring the full streaming duration.

Important: The `requestLogger` variable is accessible inside the `streamSSE` callback because it's captured from the outer `createChatRoutes` closure scope. No additional parameter passing needed.

Also add `import { performance } from 'node:perf_hooks'` if not already available. Actually, `performance` is a global in Node.js 16+, so no import needed. Just use it directly.
  </action>
  <verify>
Run `npx tsc --noEmit` to confirm no type errors. Verify the chat route file has:
1. RequestLogger parameter in createChatRoutes signature
2. setImmediate-wrapped logRequest call in non-streaming path
3. stream_options injection for streaming requests
4. Usage capture from SSE chunks in streaming path
5. setImmediate-wrapped logRequest call after [DONE] in streaming path
  </verify>
  <done>Both streaming and non-streaming chat completion requests produce fire-and-forget database log entries. Streaming requests inject stream_options.include_usage and capture token usage from the final SSE chunk. Logging never blocks HTTP response delivery.</done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes with zero errors
- `npm test` passes (existing tests still work)
- src/index.ts imports and initializes DB, creates RequestLogger, passes to chat routes, closes DB on shutdown
- src/api/routes/chat.ts accepts RequestLogger, logs non-streaming requests, captures streaming usage, logs streaming requests
- Both logging paths use setImmediate + try-catch pattern (fire-and-forget)
- Streaming requests include stream_options.include_usage in upstream body
</verification>

<success_criteria>
- Every non-streaming chat completion produces a request_logs row with accurate provider, model, token counts, latency, and HTTP status
- Every streaming chat completion produces a request_logs row (with tokens if provider supports stream_options.include_usage, zeros otherwise)
- Response latency is not affected by logging (fire-and-forget via setImmediate)
- DB initializes on startup, closes on SIGINT/SIGTERM
- Materialized aggregation tables (usage_by_provider, usage_by_chain) are automatically updated by triggers on each insert
</success_criteria>

<output>
After completion, create `.planning/phases/04-observability-persistence/04-02-SUMMARY.md`
</output>
