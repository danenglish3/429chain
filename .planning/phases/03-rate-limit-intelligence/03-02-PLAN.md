---
phase: 03-rate-limit-intelligence
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/chain/router.ts
  - src/chain/__tests__/router.test.ts
autonomous: true

must_haves:
  truths:
    - "After a successful non-streaming response, rate limit headers are parsed and quota is updated in the tracker"
    - "After a successful streaming response, rate limit headers are parsed and quota is updated in the tracker"
    - "Token limit exhaustion (remainingTokens === 0) triggers proactive marking just like request limits"
    - "Proactive exhaustion from headers in streaming path works identically to non-streaming"
  artifacts:
    - path: "src/chain/router.ts"
      provides: "updateQuota calls in both executeChain and executeStreamChain after successful responses"
      exports: ["executeChain", "executeStreamChain"]
    - path: "src/chain/__tests__/router.test.ts"
      provides: "Tests for proactive quota tracking in both chain execution paths"
      min_lines: 300
  key_links:
    - from: "src/chain/router.ts"
      to: "src/ratelimit/tracker.ts"
      via: "tracker.updateQuota() call after successful response"
      pattern: "tracker\\.updateQuota"
    - from: "src/chain/router.ts"
      to: "adapter.parseRateLimitHeaders"
      via: "Header parsing on success path"
      pattern: "parseRateLimitHeaders"
---

<objective>
Wire the extended rate limit tracker into both chain routers (non-streaming and streaming) so that every successful response updates quota tracking, enabling proactive provider skipping.

Purpose: The tracker now has updateQuota() from Plan 01. This plan wires it into the actual request flow so quota data is captured from every response. This is what makes the system proactive -- after this plan, providers are marked exhausted from header data, not just from 429 errors.

Output: Both executeChain and executeStreamChain call tracker.updateQuota() after successful responses, with tests covering proactive exhaustion from both request and token limits.
</objective>

<execution_context>
@C:\Users\danen\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\danen\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-rate-limit-intelligence/03-RESEARCH.md
@.planning/phases/03-rate-limit-intelligence/03-01-SUMMARY.md

@src/chain/router.ts
@src/chain/__tests__/router.test.ts
@src/providers/types.ts
@src/ratelimit/tracker.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Replace inline proactive check with updateQuota in executeChain</name>
  <files>
    src/chain/router.ts
    src/chain/__tests__/router.test.ts
  </files>
  <action>
    In executeChain (non-streaming path), replace the existing inline proactive exhaustion check (lines 68-78 which only check remainingRequests === 0) with a single call to tracker.updateQuota().

    Current code to replace (approximately lines 67-78):
    ```
    const rateLimitInfo = adapter.parseRateLimitHeaders(result.headers);
    if (rateLimitInfo && rateLimitInfo.remainingRequests === 0) {
      const cooldownMs = rateLimitInfo.resetRequestsMs ?? undefined;
      tracker.markExhausted(
        entry.providerId,
        entry.model,
        cooldownMs,
        'proactive: remaining requests = 0',
      );
    }
    ```

    Replace with:
    ```typescript
    const rateLimitInfo = adapter.parseRateLimitHeaders(result.headers);
    if (rateLimitInfo) {
      tracker.updateQuota(entry.providerId, entry.model, rateLimitInfo);
    }
    ```

    This is simpler AND more complete: updateQuota handles both request AND token limit checks, plus stores quota data for the 'tracking' state. The old code only checked remainingRequests.

    Add tests to router.test.ts in a new describe block 'Proactive quota tracking':
    1. Test: successful response with headers calls tracker.updateQuota (spy on tracker)
    2. Test: successful response with remainingTokens === 0 results in provider being exhausted on next call
    3. Test: successful response with remaining > 0 leaves provider available (tracking state)
    4. Test: successful response with no rate limit headers does NOT call updateQuota

    For these tests, create mock adapters that return specific RateLimitInfo from parseRateLimitHeaders. Use vi.spyOn(tracker, 'updateQuota') to verify the call.
  </action>
  <verify>
    `npx tsc --noEmit` passes with zero errors.
    `npx vitest run src/chain` passes all existing + new tests.
  </verify>
  <done>
    executeChain calls tracker.updateQuota() on every successful response with headers.
    Both request and token limit exhaustion are now proactively tracked.
    4+ new tests covering proactive quota tracking in non-streaming path.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add updateQuota call to executeStreamChain after successful stream open</name>
  <files>
    src/chain/router.ts
    src/chain/__tests__/router.test.ts
  </files>
  <action>
    In executeStreamChain (streaming path), add rate limit header parsing and quota tracking AFTER a successful stream connection is established. Currently, executeStreamChain does NOT parse rate limit headers from the streaming Response at all.

    After the `const response = await adapter.chatCompletionStream(...)` succeeds and before the return statement, add:
    ```typescript
    // Parse rate limit headers from streaming response (headers available before body consumed)
    const rateLimitInfo = adapter.parseRateLimitHeaders(response.headers);
    if (rateLimitInfo) {
      tracker.updateQuota(entry.providerId, entry.model, rateLimitInfo);
    }
    ```

    This addresses Research Open Question #4: "Should streaming responses parse rate limit headers proactively?" -- Answer: Yes. The Response object has headers available immediately even though the body ReadableStream hasn't been consumed.

    Add tests to the 'Proactive quota tracking' describe block (or new sub-describe):
    1. Test: streaming response with rate limit headers calls tracker.updateQuota
    2. Test: streaming response with remainingRequests === 0 marks provider exhausted
    3. Test: streaming response without rate limit headers does NOT call updateQuota

    For streaming tests, mock chatCompletionStream to return a Response object with custom headers. The mock Response needs headers that parseRateLimitHeaders can read. Use `new Response('', { headers: { 'x-ratelimit-remaining-requests': '0', ... } })`.
  </action>
  <verify>
    `npx tsc --noEmit` passes with zero errors.
    `npx vitest run src/chain` passes all existing + new tests.
    `npx vitest run` (full suite) passes.
  </verify>
  <done>
    executeStreamChain parses rate limit headers from streaming Response and calls tracker.updateQuota().
    Streaming and non-streaming paths have parity for proactive quota tracking.
    3+ new tests covering streaming quota tracking.
    All existing tests pass (no regression).
  </done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes
- `npx vitest run` passes full test suite
- Both executeChain and executeStreamChain call tracker.updateQuota() after successful responses
- Proactive exhaustion works for BOTH request limits AND token limits
- Streaming responses have header parsing parity with non-streaming
</verification>

<success_criteria>
- The inline proactive check in executeChain is replaced with tracker.updateQuota()
- executeStreamChain now parses rate limit headers (previously it did not)
- Both paths handle request AND token limit exhaustion
- 7+ new tests covering proactive tracking in both paths
- Zero test regressions
</success_criteria>

<output>
After completion, create `.planning/phases/03-rate-limit-intelligence/03-02-SUMMARY.md`
</output>
